import type { BotConfig } from "./config.js";
import type { CommandExecutor } from "../utils/exec.js";
import type { Logger } from "../utils/logger.js";
import type { DiffChunk } from "../git/diff.js";
import { assessPatchBehaviorRisk } from "./behavior-guard.js";

export interface DiffExtractor {
  resolveRangeFromEvent(eventPath?: string): Promise<{ baseSha: string; headSha: string }>;
  extract(
    baseSha: string,
    headSha: string
  ): Promise<{
    baseSha: string;
    headSha: string;
    changedFiles: string[];
    excludedFiles: string[];
    fullDiff: string;
    chunks: DiffChunk[];
  } | null>;
}

export interface PatchGeneratorPort {
  generate(input: {
    repository: string;
    baseRef: string;
    headRef: string;
    chunks: DiffChunk[];
  }): Promise<{
    patches: Array<{
      patch: string;
      chunk: DiffChunk;
    }>;
    skippedChunks: number;
    failedChunks: number;
    failureBreakdown: {
      timeout: number;
      invalid_output: number;
      api_error: number;
      unknown: number;
    };
  }>;
  repairPatch(input: {
    repository: string;
    baseRef: string;
    headRef: string;
    chunk: DiffChunk;
    failedPatch: string;
    applyError: string;
  }): Promise<string | null>;
}

export interface ApplyEngine {
  applyUnifiedDiff(patch: string): Promise<void>;
  hasStagedChanges(): Promise<boolean>;
  listStagedFiles(): Promise<string[]>;
}

export interface BranchManager {
  configureIdentity(identity: { name: string; email: string }): Promise<void>;
  createBranch(branchName: string): Promise<void>;
  commitAll(message: string): Promise<void>;
  pushBranch(branchName: string): Promise<void>;
}

export interface RepoScanner {
  scanSummary(): Promise<{
    trackedFileCount: number;
    topLevelDirectories: string[];
  }>;
}

export interface PullRequestCreator {
  create(request: {
    owner: string;
    repo: string;
    title: string;
    body: string;
    head: string;
    base: string;
  }): Promise<{ url: string; number: number }>;
}

export interface PipelineDependencies {
  config: BotConfig;
  logger: Logger;
  diffExtractor: DiffExtractor;
  patchGenerator: PatchGeneratorPort;
  applyEngine: ApplyEngine;
  branchManager: BranchManager;
  repoScanner: RepoScanner;
  prCreator: PullRequestCreator;
  executor: CommandExecutor;
}

export type PipelineResult =
  | {
      status: "skipped";
      reason: "no_diff" | "no_patch" | "test_failure" | "patch_apply_failure";
    }
  | {
      status: "skipped";
      reason: "model_failure";
      modelFailureSubtype: "timeout" | "invalid_output" | "api_error" | "unknown" | "mixed";
      failedChunks: number;
      totalChunks: number;
    }
  | {
      status: "created";
      branchName: string;
      pullRequestUrl: string;
      files: string[];
      changeSummary: string;
    };

const parseRepository = (repository: string): { owner: string; repo: string } => {
  const [owner, repo] = repository.split("/");
  if (!owner || !repo) {
    throw new Error(`Invalid GITHUB_REPOSITORY value: ${repository}`);
  }

  return { owner, repo };
};

const timestampForBranch = (): string => {
  const iso = new Date().toISOString();
  return iso.replace(/[-:T]/g, "").slice(0, 14);
};

const normalizePatchedPath = (value: string): string => {
  const trimmed = value.trim();
  if (trimmed === "/dev/null") {
    return trimmed;
  }

  if (trimmed.startsWith("a/") || trimmed.startsWith("b/")) {
    return trimmed.slice(2);
  }

  return trimmed;
};

const extractPatchedFiles = (patch: string): string[] => {
  const files = new Set<string>();
  const lines = patch.split("\n");

  for (const line of lines) {
    if (line.startsWith("diff --git ")) {
      const parts = line.split(" ");
      const right = parts[3];
      if (right) {
        const normalized = normalizePatchedPath(right);
        if (normalized !== "/dev/null") {
          files.add(normalized);
        }
      }
      continue;
    }

    if (line.startsWith("+++ ")) {
      const file = line.slice(4);
      const normalized = normalizePatchedPath(file);
      if (normalized !== "/dev/null") {
        files.add(normalized);
      }
    }
  }

  return [...files];
};

const buildPrBody = (files: string[], context: { baseSha: string; headSha: string }): string => {
  const list = files.length > 0 ? files.map((file) => `- ${file}`).join("\n") : "- (none)";

  return [
    "## Summary",
    "",
    "This PR contains automated refactor and optimization suggestions generated by MiniMax.",
    "",
    "## Files Updated",
    list,
    "",
    "## Source Range",
    `- Base: ${context.baseSha}`,
    `- Head: ${context.headSha}`,
    "",
    "No intended behavior changes."
  ].join("\n");
};

const deriveModelFailureSubtype = (failureBreakdown: {
  timeout: number;
  invalid_output: number;
  api_error: number;
  unknown: number;
}): "timeout" | "invalid_output" | "api_error" | "unknown" | "mixed" => {
  const entries = Object.entries(failureBreakdown).filter(([, count]) => count > 0);
  if (entries.length === 0) {
    return "unknown";
  }

  if (entries.length > 1) {
    return "mixed";
  }

  const subtype = entries[0]?.[0];
  if (
    subtype === "timeout" ||
    subtype === "invalid_output" ||
    subtype === "api_error" ||
    subtype === "unknown"
  ) {
    return subtype;
  }

  return "unknown";
};

export class RefactorPipeline {
  private readonly deps: PipelineDependencies;

  public constructor(deps: PipelineDependencies) {
    this.deps = deps;
  }

  public async run(): Promise<PipelineResult> {
    const {
      config,
      logger,
      diffExtractor,
      patchGenerator,
      applyEngine,
      branchManager,
      repoScanner,
      prCreator,
      executor
    } = this.deps;

    const range = await diffExtractor.resolveRangeFromEvent(config.eventPath);
    const diffContext = await diffExtractor.extract(range.baseSha, range.headSha);

    if (!diffContext) {
      logger.info("Skipping run because no diff was detected");
      return { status: "skipped", reason: "no_diff" };
    }

    if (diffContext.excludedFiles.length > 0) {
      logger.info("Excluded files from AI analysis", {
        excludedFileCount: diffContext.excludedFiles.length,
        excludedFiles: diffContext.excludedFiles
      });
    }

    const repoSummary = await repoScanner.scanSummary();
    logger.debug("Repository scanned", repoSummary);

    const patchResult = await patchGenerator.generate({
      repository: config.repository,
      baseRef: diffContext.baseSha,
      headRef: diffContext.headSha,
      chunks: diffContext.chunks
    });

    if (patchResult.failedChunks > 0) {
      logger.warn("Some MiniMax chunks failed and were skipped", {
        failedChunks: patchResult.failedChunks,
        totalChunks: diffContext.chunks.length,
        failureBreakdown: patchResult.failureBreakdown
      });
    }

    if (patchResult.failedChunks > 0 && patchResult.patches.length === 0) {
      const modelFailureSubtype = deriveModelFailureSubtype(patchResult.failureBreakdown);
      logger.warn("No usable patches generated and model failures occurred, skipping PR creation", {
        modelFailureSubtype,
        failedChunks: patchResult.failedChunks,
        totalChunks: diffContext.chunks.length
      });

      return {
        status: "skipped",
        reason: "model_failure",
        modelFailureSubtype,
        failedChunks: patchResult.failedChunks,
        totalChunks: diffContext.chunks.length
      };
    }

    if (patchResult.patches.length === 0) {
      logger.info("MiniMax reported no patch changes for this diff", {
        skippedChunks: patchResult.skippedChunks,
        failedChunks: patchResult.failedChunks
      });
      return { status: "skipped", reason: "no_patch" };
    }

    try {
      let appliedPatchCount = 0;
      for (const generated of patchResult.patches) {
        let currentPatch = generated.patch;
        let applySucceeded = false;
        let lastError = "";

        for (let attempt = 0; attempt <= config.patchRepairAttempts; attempt += 1) {
          try {
            const touchedFiles = extractPatchedFiles(currentPatch);
            const unauthorizedFiles = touchedFiles.filter((file) => !generated.chunk.files.includes(file));

            if (unauthorizedFiles.length > 0) {
              throw new Error(
                `Patch touched files outside chunk scope: ${unauthorizedFiles.join(", ")}`
              );
            }

            if (config.behaviorGuardMode === "strict") {
              const guard = assessPatchBehaviorRisk(currentPatch);
              if (!guard.safe) {
                throw new Error(`Behavior guard blocked patch: ${guard.reasons.join("; ")}`);
              }
            }

            await applyEngine.applyUnifiedDiff(currentPatch);
            applySucceeded = true;
            appliedPatchCount += 1;
            break;
          } catch (error) {
            lastError = error instanceof Error ? error.message : String(error);

            if (attempt === config.patchRepairAttempts) {
              break;
            }

            logger.warn("Patch apply failed, requesting repair patch", {
              attempt: attempt + 1,
              maxAttempts: config.patchRepairAttempts,
              applyError: lastError
            });

            const repairedPatch = await patchGenerator.repairPatch({
              repository: config.repository,
              baseRef: diffContext.baseSha,
              headRef: diffContext.headSha,
              chunk: generated.chunk,
              failedPatch: currentPatch,
              applyError: lastError
            });

            if (!repairedPatch) {
              lastError = "MiniMax repair did not produce a patch";
              break;
            }

            currentPatch = repairedPatch;
          }
        }

        if (!applySucceeded) {
          if (lastError.startsWith("Behavior guard blocked patch") || lastError === "MiniMax repair did not produce a patch") {
            logger.info("Skipping patch after behavior guard/retry evaluation", { reason: lastError });
            continue;
          }

          throw new Error(lastError || "Patch apply failed");
        }
      }

      if (appliedPatchCount === 0) {
        logger.info("No patches were applied after behavior guard and repair attempts");
        return { status: "skipped", reason: "no_patch" };
      }
    } catch (error) {
      logger.warn("Patch application failed, skipping PR creation", {
        error: error instanceof Error ? error.message : String(error)
      });
      return { status: "skipped", reason: "patch_apply_failure" };
    }

    const hasChanges = await applyEngine.hasStagedChanges();
    if (!hasChanges) {
      logger.info("No staged changes after applying MiniMax patches");
      return { status: "skipped", reason: "no_patch" };
    }

    try {
      const [testCommand, ...testArgs] = config.testCommand.split(" ").filter(Boolean);
      if (!testCommand) {
        throw new Error("TEST_COMMAND resolved to an empty command");
      }
      await executor.run(testCommand, testArgs, { timeoutMs: config.timeoutMs });
    } catch (error) {
      logger.warn("Tests failed after applying patch, skipping PR creation", {
        error: error instanceof Error ? error.message : String(error)
      });
      return { status: "skipped", reason: "test_failure" };
    }

    const files = await applyEngine.listStagedFiles();
    let changeSummary = "staged changes";
    try {
      const shortStat = (await executor.run("git", ["diff", "--cached", "--shortstat"])).trim();
      if (shortStat) {
        changeSummary = shortStat;
      }
    } catch (error) {
      logger.warn("Failed to compute staged change summary", {
        error: error instanceof Error ? error.message : String(error)
      });
    }

    const branchName = `refactor/minimax-${timestampForBranch()}`;
    await branchManager.configureIdentity({
      name: process.env.GIT_AUTHOR_NAME ?? "minimax-refactor-bot",
      email: process.env.GIT_AUTHOR_EMAIL ?? "bot@users.noreply.github.com"
    });
    await branchManager.createBranch(branchName);
    await branchManager.commitAll("auto: minimax refactor & optimization");
    await branchManager.pushBranch(branchName);

    const parsed = parseRepository(config.repository);
    const pullRequest = await prCreator.create({
      owner: parsed.owner,
      repo: parsed.repo,
      title: "auto: minimax refactor & optimization",
      body: buildPrBody(files, {
        baseSha: diffContext.baseSha,
        headSha: diffContext.headSha
      }),
      head: branchName,
      base: config.baseBranch
    });

    logger.info("Created refactor PR", { url: pullRequest.url, branchName, filesChanged: files.length });

    return {
      status: "created",
      branchName,
      pullRequestUrl: pullRequest.url,
      files,
      changeSummary
    };
  }
}
